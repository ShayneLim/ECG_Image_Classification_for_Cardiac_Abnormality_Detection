{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f04a7b-d67e-4181-8f60-3003c20232cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export train:   0%|                          | 50/17084 [00:03<18:57, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] saved 50 images → /Users/shayne/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export val:   1%|▎                            | 20/2146 [00:01<01:57, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] saved 20 images → /Users/shayne/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export test:   1%|▎                           | 20/2158 [00:01<02:03, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] saved 20 images → /Users/shayne/test\n",
      "/Users/shayne/train/MI/77.png\n",
      "/Users/shayne/train/MI/50.png\n",
      "/Users/shayne/train/STTC/22.png\n",
      "/Users/shayne/train/STTC/54.png\n",
      "/Users/shayne/train/HYP/45.png\n"
     ]
    }
   ],
   "source": [
    "import os, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# set base folder\n",
    "DB = r\"/Users/shayne/Documents/SUNWAY_UNI/sem8/capstone 1/dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\" # <- path to the PTB-XL folder\n",
    "OUT_ROOT = r\"/Users/shayne\"        # png saved here\n",
    "\n",
    "FNAME_COL = \"filename_lr\"                      \n",
    "SR = 100      \n",
    "# 1600 x 1200\n",
    "TARGET_SIZE = (800, 600)                       # output image width × height (pixels)\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "# read metadata CSVs\n",
    "df = pd.read_csv(os.path.join(DB, \"ptbxl_database.csv\"))\n",
    "scp = pd.read_csv(os.path.join(DB, \"scp_statements.csv\"), index_col=0)\n",
    "\n",
    "# keep only diagnostic statements\n",
    "diagnostic_codes = scp[scp[\"diagnostic\"] == 1]\n",
    "\n",
    "\n",
    "#map scp_codes convert to diagnostic superclasses\n",
    "def to_superclasses(scp_codes_str):\n",
    "    codes = ast.literal_eval(scp_codes_str)  # dict: code → weight\n",
    "    diags = [c for c in codes.keys() if c in diagnostic_codes.index]\n",
    "    supers = sorted({diagnostic_codes.loc[c, \"diagnostic_class\"] for c in diags})\n",
    "    return supers\n",
    "\n",
    "df[\"superclasses\"] = df[\"scp_codes\"].apply(to_superclasses)\n",
    "\n",
    "# official stratified folds\n",
    "\n",
    "train_df = df[df[\"strat_fold\"].isin(range(1, 9))].copy()\n",
    "val_df   = df[df[\"strat_fold\"] == 9].copy()\n",
    "test_df  = df[df[\"strat_fold\"] == 10].copy()\n",
    "\n",
    "\n",
    "#single-label primary class per record\n",
    "# if an entry has multiple super classes, pick one based on the priority shown below\n",
    "PRIORITY = [\"MI\", \"STTC\", \"HYP\", \"CD\", \"NORM\"]\n",
    "\n",
    "# function that picks a super class \n",
    "def choose_primary_superclass(superclasses):\n",
    "    if not superclasses:\n",
    "        return None\n",
    "    for c in PRIORITY:\n",
    "        if c in superclasses:\n",
    "            return c\n",
    "    return superclasses[0]\n",
    "\n",
    "# create a new column called primary class and apply the result of the super class function to it\n",
    "for split in (train_df, val_df, test_df):\n",
    "    split[\"primary_class\"] = split[\"superclasses\"].apply(choose_primary_superclass)\n",
    "\n",
    "# drop the rows that have no primary class \n",
    "train_df = train_df.dropna(subset=[\"primary_class\"])\n",
    "val_df   = val_df.dropna(subset=[\"primary_class\"])\n",
    "test_df  = test_df.dropna(subset=[\"primary_class\"])\n",
    "\n",
    "\n",
    "# helpers for reading WFDB and saving plots\n",
    "\n",
    "def load_signal_and_leads(rec_rel_path, base_dir=DB):\n",
    "    \"\"\"Read WFDB record. Returns (signal[T,12], lead_names[list]).\"\"\"\n",
    "    rec_path = os.path.join(base_dir, rec_rel_path)\n",
    "    sig, meta = wfdb.rdsamp(rec_path)\n",
    "    names = list(meta.sig_name) if hasattr(meta, \"sig_name\") else [f\"Lead{i+1}\" for i in range(sig.shape[1])]\n",
    "    return sig.astype(\"float32\"), names\n",
    "    \n",
    "\n",
    "# algorithm that turns the waveform data into plots\n",
    "# 12 leads per image in this case\n",
    "def save_12lead_strip(signal, lead_names, out_path, sr=SR, target_size=TARGET_SIZE):\n",
    "    \"\"\"Plot 12 leads in a 3×4 grid and save as PNG.\"\"\"\n",
    "    T, C = signal.shape\n",
    "    fig_w, fig_h = 10, 6\n",
    "    dpi = min(target_size[0]/fig_w, target_size[1]/fig_h)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    axes = axes.ravel()\n",
    "    t = np.arange(T) / float(sr)\n",
    "\n",
    "    for i in range(min(C, 12)):\n",
    "        ax = axes[i]\n",
    "        ax.plot(t, signal[:, i], linewidth=0.8)\n",
    "        # ax.set_title(lead_names[i] if i < len(lead_names) else f\"Lead {i+1}\", fontsize=8)\n",
    "        ax.set_xlim([t[0], t[-1]])\n",
    "        ax.axis(\"off\")\n",
    "    for j in range(C, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(pad=0.15)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\", pad_inches=0.03)\n",
    "    plt.close(fig)\n",
    "\n",
    "# saves the plots into iamges with good file directory and names\n",
    "def export_split_images(split_df, split_name, limit=None):\n",
    "    \"\"\"Save ECG plots into OUT_ROOT/split_name/<class>/<ecg_id>.png.\"\"\"\n",
    "    saved = 0\n",
    "    for _, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Export {split_name}\"):\n",
    "        if limit and saved >= limit:\n",
    "            break\n",
    "        label = row[\"primary_class\"]\n",
    "        if not label:\n",
    "            continue\n",
    "        try:\n",
    "            signal, leads = load_signal_and_leads(row[FNAME_COL])\n",
    "        except Exception as e:\n",
    "            # print(\"Failed:\", row[FNAME_COL], e)\n",
    "            continue\n",
    "\n",
    "        ecg_id = int(row[\"ecg_id\"]) if \"ecg_id\" in row else _\n",
    "        out_path = os.path.join(OUT_ROOT, split_name, label, f\"{ecg_id}.png\")\n",
    "        save_12lead_strip(signal, leads, out_path)\n",
    "        saved += 1\n",
    "    print(f\"[{split_name}] saved {saved} images → {os.path.join(OUT_ROOT, split_name)}\")\n",
    "\n",
    "\n",
    "# run export (try small limits first)\n",
    "export_split_images(train_df, \"train\", limit=50)\n",
    "export_split_images(val_df,   \"val\",   limit=20)\n",
    "export_split_images(test_df,  \"test\",  limit=20)\n",
    "\n",
    "\n",
    "# preview a few saved images\n",
    "some = glob.glob(os.path.join(OUT_ROOT, \"train\", \"*\", \"*.png\"))[:5]\n",
    "for p in some:\n",
    "    print(p)\n",
    "    img = Image.open(p)\n",
    "    img.show()  # opens in default image viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d296bc9-93e9-4fa7-ab32-43cf8b15d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 50 rows → /Users/shayne/train_labels.csv\n",
      "Wrote 20 rows → /Users/shayne/val_labels.csv\n",
      "Wrote 20 rows → /Users/shayne/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "\n",
    "\n",
    "# maps the class into binary as below\n",
    "def to_multihot(superclasses):\n",
    "    s = set(superclasses)\n",
    "    return {c: int(c in s) for c in CLASS_ORDER}\n",
    "\n",
    "def build_labels_csv_from_existing(split_df, split_name, out_root=OUT_ROOT):\n",
    "    \n",
    "    # empty rows to store all entries\n",
    "    rows = []\n",
    "    # the directory of the split (train/val/test)\n",
    "    split_dir = os.path.join(out_root, split_name)\n",
    "    # for each entry in the dataframe [id, name, superclass, primaryclass]\n",
    "    for _, r in split_df.iterrows():\n",
    "        # we get the super class\n",
    "        supers = r[\"superclasses\"]          # e.g., ['CD','HYP']\n",
    "        # if no superclass, then this entry is meaningless\n",
    "        if not supers:\n",
    "            continue\n",
    "        # get primary class\n",
    "        primary = r[\"primary_class\"]\n",
    "        # get the id of the ecg\n",
    "        ecg_id = int(r[\"ecg_id\"])\n",
    "        # find the image that we saved that corresponds to the entry we're lookniga t right now\n",
    "        img_path = os.path.join(split_dir, primary, f\"{ecg_id}.png\")\n",
    "        if not os.path.exists(img_path):\n",
    "            # might not exist if you used a small 'limit' during export\n",
    "            continue\n",
    "\n",
    "        # creates a multihot row\n",
    "        mh = to_multihot(supers)\n",
    "        row = {\n",
    "            \"image_path\": img_path.replace(\"\\\\\", \"/\"),\n",
    "            \"labels\": json.dumps(sorted(supers))\n",
    "        }\n",
    "        # add the columns\n",
    "        row.update(mh)                      # add NORM/MI/STTC/HYP/CD columns\n",
    "        # add the rows\n",
    "        rows.append(row)\n",
    "      \n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(out_root, f\"{split_name}_labels.csv\")\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {len(df_out)} rows → {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "# build csvs for all splits\n",
    "train_csv = build_labels_csv_from_existing(train_df, \"train\")\n",
    "val_csv   = build_labels_csv_from_existing(val_df,   \"val\")\n",
    "test_csv  = build_labels_csv_from_existing(test_df,  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cddf0-a05f-43ec-9f58-78550cdbaf57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
