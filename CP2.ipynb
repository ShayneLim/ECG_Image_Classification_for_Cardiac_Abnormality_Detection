{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f04a7b-d67e-4181-8f60-3003c20232cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export train:   0%|                          | 50/17084 [00:02<15:19, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] saved 50 images → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export val:   1%|▎                            | 20/2146 [00:01<01:54, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val] saved 20 images → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export test:   1%|▎                           | 20/2158 [00:01<01:59, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] saved 20 images → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/test\n",
      "/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train/MI/77.png\n",
      "/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train/MI/50.png\n",
      "/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train/STTC/22.png\n",
      "/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train/STTC/54.png\n",
      "/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train/HYP/45.png\n"
     ]
    }
   ],
   "source": [
    "import os, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# set base folder\n",
    "DB = r\"/Users/shayne/Documents/SUNWAY_UNI/sem8/capstone 1/dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\" # <- path to the PTB-XL folder\n",
    "OUT_ROOT = r\"/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images\"        # png saved here\n",
    "\n",
    "FNAME_COL = \"filename_lr\"                      \n",
    "SR = 100      \n",
    "# 1600 x 1200\n",
    "TARGET_SIZE = (800, 600)                       # output image width × height (pixels)\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "\n",
    "# read metadata CSVs\n",
    "df = pd.read_csv(os.path.join(DB, \"ptbxl_database.csv\"))\n",
    "scp = pd.read_csv(os.path.join(DB, \"scp_statements.csv\"), index_col=0)\n",
    "\n",
    "# keep only diagnostic statements\n",
    "diagnostic_codes = scp[scp[\"diagnostic\"] == 1]\n",
    "\n",
    "\n",
    "#map scp_codes convert to diagnostic superclasses\n",
    "def to_superclasses(scp_codes_str):\n",
    "    codes = ast.literal_eval(scp_codes_str)  # dict: code → weight\n",
    "    diags = [c for c in codes.keys() if c in diagnostic_codes.index]\n",
    "    supers = sorted({diagnostic_codes.loc[c, \"diagnostic_class\"] for c in diags})\n",
    "    return supers\n",
    "\n",
    "df[\"superclasses\"] = df[\"scp_codes\"].apply(to_superclasses)\n",
    "\n",
    "# official stratified folds\n",
    "\n",
    "train_df = df[df[\"strat_fold\"].isin(range(1, 9))].copy()\n",
    "val_df   = df[df[\"strat_fold\"] == 9].copy()\n",
    "test_df  = df[df[\"strat_fold\"] == 10].copy()\n",
    "\n",
    "\n",
    "#single-label primary class per record\n",
    "# if an entry has multiple super classes, pick one based on the priority shown below\n",
    "PRIORITY = [\"MI\", \"STTC\", \"HYP\", \"CD\", \"NORM\"]\n",
    "\n",
    "# function that picks a super class \n",
    "def choose_primary_superclass(superclasses):\n",
    "    if not superclasses:\n",
    "        return None\n",
    "    for c in PRIORITY:\n",
    "        if c in superclasses:\n",
    "            return c\n",
    "    return superclasses[0]\n",
    "\n",
    "# create a new column called primary class and apply the result of the super class function to it\n",
    "for split in (train_df, val_df, test_df):\n",
    "    split[\"primary_class\"] = split[\"superclasses\"].apply(choose_primary_superclass)\n",
    "\n",
    "# drop the rows that have no primary class \n",
    "train_df = train_df.dropna(subset=[\"primary_class\"])\n",
    "val_df   = val_df.dropna(subset=[\"primary_class\"])\n",
    "test_df  = test_df.dropna(subset=[\"primary_class\"])\n",
    "\n",
    "\n",
    "# helpers for reading WFDB and saving plots\n",
    "\n",
    "def load_signal_and_leads(rec_rel_path, base_dir=DB):\n",
    "    \"\"\"Read WFDB record. Returns (signal[T,12], lead_names[list]).\"\"\"\n",
    "    rec_path = os.path.join(base_dir, rec_rel_path)\n",
    "    sig, meta = wfdb.rdsamp(rec_path)\n",
    "    names = list(meta.sig_name) if hasattr(meta, \"sig_name\") else [f\"Lead{i+1}\" for i in range(sig.shape[1])]\n",
    "    return sig.astype(\"float32\"), names\n",
    "    \n",
    "\n",
    "# algorithm that turns the waveform data into plots\n",
    "# 12 leads per image in this case\n",
    "def save_12lead_strip(signal, lead_names, out_path, sr=SR, target_size=TARGET_SIZE):\n",
    "    \"\"\"Plot 12 leads in a 3×4 grid and save as PNG.\"\"\"\n",
    "    T, C = signal.shape\n",
    "    fig_w, fig_h = 10, 6\n",
    "    dpi = min(target_size[0]/fig_w, target_size[1]/fig_h)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(fig_w, fig_h), dpi=dpi)\n",
    "    axes = axes.ravel()\n",
    "    t = np.arange(T) / float(sr)\n",
    "\n",
    "    for i in range(min(C, 12)):\n",
    "        ax = axes[i]\n",
    "        ax.plot(t, signal[:, i], linewidth=0.8)\n",
    "        # ax.set_title(lead_names[i] if i < len(lead_names) else f\"Lead {i+1}\", fontsize=8)\n",
    "        ax.set_xlim([t[0], t[-1]])\n",
    "        ax.axis(\"off\")\n",
    "    for j in range(C, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(pad=0.15)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\", pad_inches=0.03)\n",
    "    plt.close(fig)\n",
    "\n",
    "# saves the plots into iamges with good file directory and names\n",
    "def export_split_images(split_df, split_name, limit=None):\n",
    "    \"\"\"Save ECG plots into OUT_ROOT/split_name/<class>/<ecg_id>.png.\"\"\"\n",
    "    saved = 0\n",
    "    for _, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Export {split_name}\"):\n",
    "        if limit and saved >= limit:\n",
    "            break\n",
    "        label = row[\"primary_class\"]\n",
    "        if not label:\n",
    "            continue\n",
    "        try:\n",
    "            signal, leads = load_signal_and_leads(row[FNAME_COL])\n",
    "        except Exception as e:\n",
    "            # print(\"Failed:\", row[FNAME_COL], e)\n",
    "            continue\n",
    "\n",
    "        ecg_id = int(row[\"ecg_id\"]) if \"ecg_id\" in row else _\n",
    "        out_path = os.path.join(OUT_ROOT, split_name, label, f\"{ecg_id}.png\")\n",
    "        save_12lead_strip(signal, leads, out_path)\n",
    "        saved += 1\n",
    "    print(f\"[{split_name}] saved {saved} images → {os.path.join(OUT_ROOT, split_name)}\")\n",
    "\n",
    "\n",
    "# run export (try small limits first)\n",
    "export_split_images(train_df, \"train\", limit=50)\n",
    "export_split_images(val_df,   \"val\",   limit=20)\n",
    "export_split_images(test_df,  \"test\",  limit=20)\n",
    "\n",
    "\n",
    "# preview a few saved images\n",
    "some = glob.glob(os.path.join(OUT_ROOT, \"train\", \"*\", \"*.png\"))[:5]\n",
    "for p in some:\n",
    "    print(p)\n",
    "    img = Image.open(p)\n",
    "    img.show()  # opens in default image viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbf0fa7-3f07-494d-afae-63843f5d7f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>...</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "      <th>superclasses</th>\n",
       "      <th>primary_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-09 09:17:34</td>\n",
       "      <td>...</td>\n",
       "      <td>, I-V1,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00001_lr</td>\n",
       "      <td>records500/00000/00001_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13243.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-14 12:55:37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>records100/00000/00002_lr</td>\n",
       "      <td>records500/00000/00002_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20372.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 12:49:10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>records100/00000/00003_lr</td>\n",
       "      <td>records500/00000/00003_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-15 13:44:57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00004_lr</td>\n",
       "      <td>records500/00000/00004_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1984-11-17 10:43:15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00005_lr</td>\n",
       "      <td>records500/00000/00005_hr</td>\n",
       "      <td>[NORM]</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ecg_id  patient_id   age  sex  height  weight  nurse  site     device  \\\n",
       "0       1     15709.0  56.0    1     NaN    63.0    2.0   0.0  CS-12   E   \n",
       "1       2     13243.0  19.0    0     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "2       3     20372.0  37.0    1     NaN    69.0    2.0   0.0  CS-12   E   \n",
       "3       4     17014.0  24.0    0     NaN    82.0    2.0   0.0  CS-12   E   \n",
       "4       5     17448.0  19.0    1     NaN    70.0    2.0   0.0  CS-12   E   \n",
       "\n",
       "        recording_date  ... static_noise burst_noise electrodes_problems  \\\n",
       "0  1984-11-09 09:17:34  ...    , I-V1,           NaN                 NaN   \n",
       "1  1984-11-14 12:55:37  ...          NaN         NaN                 NaN   \n",
       "2  1984-11-15 12:49:10  ...          NaN         NaN                 NaN   \n",
       "3  1984-11-15 13:44:57  ...          NaN         NaN                 NaN   \n",
       "4  1984-11-17 10:43:15  ...          NaN         NaN                 NaN   \n",
       "\n",
       "  extra_beats pacemaker  strat_fold                filename_lr  \\\n",
       "0         NaN       NaN           3  records100/00000/00001_lr   \n",
       "1         NaN       NaN           2  records100/00000/00002_lr   \n",
       "2         NaN       NaN           5  records100/00000/00003_lr   \n",
       "3         NaN       NaN           3  records100/00000/00004_lr   \n",
       "4         NaN       NaN           4  records100/00000/00005_lr   \n",
       "\n",
       "                 filename_hr  superclasses primary_class  \n",
       "0  records500/00000/00001_hr        [NORM]          NORM  \n",
       "1  records500/00000/00002_hr        [NORM]          NORM  \n",
       "2  records500/00000/00003_hr        [NORM]          NORM  \n",
       "3  records500/00000/00004_hr        [NORM]          NORM  \n",
       "4  records500/00000/00005_hr        [NORM]          NORM  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d296bc9-93e9-4fa7-ab32-43cf8b15d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 50 rows → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/train_labels.csv\n",
      "Wrote 20 rows → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/val_labels.csv\n",
      "Wrote 20 rows → /Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images/test_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "\n",
    "\n",
    "# maps the class into binary as below\n",
    "def to_multihot(superclasses):\n",
    "    s = set(superclasses)\n",
    "    result = {}\n",
    "\n",
    "    for c in CLASS_ORDER:\n",
    "        if c in s:\n",
    "            result[c] = 1\n",
    "        else:\n",
    "            result[c] = 0\n",
    "    return result\n",
    "\n",
    "def build_labels_csv_from_existing(split_df, split_name, out_root=OUT_ROOT):\n",
    "    \n",
    "    # empty rows to store all entries\n",
    "    rows = []\n",
    "    # the directory of the split (train/val/test)\n",
    "    split_dir = os.path.join(out_root, split_name)\n",
    "    # for each entry in the dataframe [id, name, superclass, primaryclass]\n",
    "    for r in split_df.iterrows():\n",
    "        r = r[1]\n",
    "        # we get the super class\n",
    "        supers = r[\"superclasses\"]          # e.g., ['CD','HYP']\n",
    "        # if no superclass, then this entry is meaningless\n",
    "        if not supers:\n",
    "            continue\n",
    "        # get primary class\n",
    "        primary = r[\"primary_class\"]\n",
    "        # get the id of the ecg\n",
    "        ecg_id = int(r[\"ecg_id\"])\n",
    "        # find the image that we saved that corresponds to the entry we're lookniga t right now\n",
    "        img_path = os.path.join(split_dir, primary, f\"{ecg_id}.png\")\n",
    "        if not os.path.exists(img_path):\n",
    "            # might not exist if you used a small 'limit' during export\n",
    "            continue\n",
    "\n",
    "        # creates a multihot row\n",
    "        mh = to_multihot(supers)\n",
    "        row = {\n",
    "            \"image_path\": img_path.replace(\"\\\\\", \"/\"),\n",
    "            \"labels\": json.dumps(sorted(supers))\n",
    "        }\n",
    "        # add the columns\n",
    "        row.update(mh)                      # add NORM/MI/STTC/HYP/CD columns\n",
    "        # add the rows\n",
    "        rows.append(row)\n",
    "      \n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(out_root, f\"{split_name}_labels.csv\")\n",
    "    df_out.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {len(df_out)} rows → {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "# build csvs for all splits\n",
    "train_csv = build_labels_csv_from_existing(train_df, \"train\")\n",
    "val_csv   = build_labels_csv_from_existing(val_df,   \"val\")\n",
    "test_csv  = build_labels_csv_from_existing(test_df,  \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4cddf0-a05f-43ec-9f58-78550cdbaf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# === Paths (update OUT_ROOT to your folder) ===\n",
    "OUT_ROOT = r\"/Users/shayne/Documents/SUNWAY_UNI/sem8/Capstone2/ecg_images\"\n",
    "train_csv = os.path.join(OUT_ROOT, \"train_labels.csv\")\n",
    "val_csv   = os.path.join(OUT_ROOT, \"val_labels.csv\")\n",
    "test_csv  = os.path.join(OUT_ROOT, \"test_labels.csv\")\n",
    "\n",
    "# Class order used everywhere\n",
    "CLASS_ORDER = [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"]\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab74920-3080-42cf-8afa-e0464567e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelECGImages(Dataset):\n",
    "    \"\"\"\n",
    "    Reads rows: image_path, labels(JSON list), and returns:\n",
    "      image tensor, multi-hot target tensor of shape [5]\n",
    "    \"\"\"\n",
    "    # The behavior\n",
    "    def __init__(self, labels_csv, transform=None):\n",
    "        self.df = pd.read_csv(labels_csv)\n",
    "        # Read csv and turn paths and labels into lists\n",
    "        # [a,b,c]\n",
    "        # [x,y,z]\n",
    "        self.paths = self.df[\"image_path\"].tolist()\n",
    "        self.labels_json = self.df[\"labels\"].tolist()\n",
    "        # transform function to apply on the data \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): \n",
    "        # returns how many images/data we have\n",
    "        return len(self.paths)\n",
    "        \n",
    "    # actions\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        # you can use RGB or true grayscale, but we mostly use grayscale\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        # if there is a transformation function, apply it\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        # Parse labels JSON → list[str] → multi-hot\n",
    "        # load the labels\n",
    "        # [NORM, MI] or other variations like [MI, STTC]\n",
    "        # json loads turns a string into an list \n",
    "        labs = json.loads(self.labels_json[idx])\n",
    "        # create a \"hot\" arrray of size CLASS_ORDER filled with zeros\n",
    "        # [NORM, \n",
    "        # [0,0,0,0,0]\n",
    "        target = torch.zeros(len(CLASS_ORDER), dtype=torch.float32)\n",
    "        # target = [0.0, 1.0, 0.0, 0.0, 0.0]\n",
    "        # for every label that matches with class order \n",
    "        # [\"NORM\", \"MI\", \"STTC\", \"HYP\", \"CD\"], fill with 1.0\n",
    "        # [NORM, MI] -> [1.0, 1.0, 0.0, 0.0, 0.0]\n",
    "        # labs = [NORM, MI]\n",
    "        for lab in labs:\n",
    "            if lab in CLASS_ORDER:\n",
    "                target[CLASS_ORDER.index(lab)] = 1.0\n",
    "        # [Image, label]\n",
    "        # [Image, [0.0, 1.0, 0.0, 0.0, 0.0]]\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ab094b-1cfd-45b6-a781-4041b7cf12bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 20, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image size to train (you can try 224 or 256)\n",
    "# 224 is a legendary image size that comes from ImageNet, which later used in AlexNet, VGG16, ResNet,\n",
    "# enough to preserve detail and small enough to fit in GPU memory with small batch sizes\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    # Light augmentation (avoid horizontal flip; it reverses time)\n",
    "    # We want it to understand small shifts in width and height, or small changes in zoom, but we do not want to make it rotate\n",
    "    # rotation matters in ecg\n",
    "    transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.02,0.02), scale=(0.98,1.02))], p=0.5),\n",
    "    # turns it into a tensor floatTensor to be exact\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# repeat the same for testing images and evaluation images\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_ds = MultiLabelECGImages(train_csv, transform=train_tfms)\n",
    "val_ds   = MultiLabelECGImages(val_csv,   transform=eval_tfms)\n",
    "test_ds  = MultiLabelECGImages(test_csv,  transform=eval_tfms)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # keep 0 on Windows to avoid issues; try 2 later\n",
    "\n",
    "\"\"\"\n",
    "# train_ds returns a dataset object (image, label)\n",
    "# batch size = 32 calls train_ds 32 times to get 32 labels making it one batch\n",
    "# when we call it in for batch_img, batch_labels in train_dl: we will split data into [32,32,32,32, ...] and for that list\n",
    "# we'll loop through it\n",
    "# num workers are just for parallel processing purposes (by default it'll run in parallel)\n",
    "# pin memory locks a part of the cpu so that nothing can overwrite it, therefore gpu never accesses\n",
    "# the wrong data\n",
    "\"\"\"\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c4e175a-e4f0-4fcb-b7f0-5e4be0ccb3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1628, 24.0000, 24.0000, 49.0000,  9.0000], device='mps:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "funny thing about imbalanced models 75-25\n",
    "\n",
    "the classes are not balanced, there are way more NORM than everything else\n",
    "assume a 75-25 ratio. due to this imbalance, we must make the model care \n",
    "just as much about the minority (25) through heavy penalties\n",
    "\"\"\"\n",
    "def compute_pos_weight(labels_csv):\n",
    "    df = pd.read_csv(labels_csv)\n",
    "    # Expect columns NORM, MI, STTC, HYP, CD as 0/1 flags\n",
    "    # load training labels only because thats what we train on\n",
    "    # count the number of positives per class\n",
    "    # returns smth like [1200,80,250,200,90] just an example\n",
    "    counts_pos = df[CLASS_ORDER].sum().values.astype(np.float32) \n",
    "    # find out which classs are rare or common\n",
    "    counts_all = len(df)\n",
    "    counts_neg = counts_all - counts_pos\n",
    "    # Avoid division by zero\n",
    "    # calculate the weights\n",
    "    pos_weight = counts_neg / np.clip(counts_pos, 1.0, None)\n",
    "    # the weights tell us how heavily we should penalize for failing to recognize \n",
    "    # certain classes (what does this remind u of?)\n",
    "    return torch.tensor(pos_weight, dtype=torch.float32)\n",
    "\n",
    "pos_weight = compute_pos_weight(train_csv).to(device)\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5094981-1e40-4325-8cfe-235e4876cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Two 3×3 convs with BN+ReLU. Keeps H,W; downsampling happens in the following MaxPool.\"\"\"\n",
    "    # building neural networks with classes is we need to define two things\n",
    "    # properties and behavior \n",
    "    # runner \n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        # input channel = 3 (RGB), filter number (3x3 stencil), padding to make sure stencil stays on edge\n",
    "        # bias = False, we'll handle it in bn1\n",
    "        # convolution runs a filter on an input noting its variations, patterns, nuances, etc\n",
    "        # we do this many times across many layers to \"learn\" a pattern\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        # batch normalizer stabilizes and normalizes activations\n",
    "        # recentering / rescaling inputs to a predictable range\n",
    "        # activations (outputs) -> channel/node (layer) \n",
    "        self.bn1   = nn.BatchNorm2d(out_c)\n",
    "        # repeats but this time instead of 3 -> 32, we'll look 32 -> 32\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # previously we defined how our model should work\n",
    "        # forward function runs our model exactly n times (given you call it n times)\n",
    "        # relu (adds non linearity)\n",
    "        # image -> conv1 -> bn -> relu -> features\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # conv → BN → ReLU\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # conv → BN → ReLU\n",
    "        return x\n",
    "\n",
    "class ECGStripCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple-but-solid CNN for 224x224 RGB images:\n",
    "    4 stages (channels: 32, 64, 128, 256) with MaxPool after each stage,\n",
    "    then global average pooling and a small classifier head to 5 logits.\n",
    "\n",
    "    basically: \n",
    "    pattern spotters - convolutions\n",
    "    zoom-out step - pooling \n",
    "    summary clipboard - global average pooling\n",
    "    final judge - linear head that outputs 5 scores (1 per diagnosis)\n",
    "\n",
    "    input: [B, 3, 224, 224] (B (optional), C, H, W)\n",
    "    output: [B, 5] logits (5 classes)\n",
    "\n",
    "    conv block basically marks every possible pattern/evidence it can find\n",
    "    maxpool grabs the most convincing/relevant one from each segment (igores noise)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=5, dropout_p=0.3):\n",
    "        super().__init__()\n",
    "        # conv block outputs 32 pattern maps\n",
    "        self.stage1 = ConvBlock(3,32)   # [B,3,224,224] -> [B,32,224,224]\n",
    "        # for all the pattterns maxpool (2x2) allows the maxpool\n",
    "        # filter to traverse and generalize\n",
    "        # after each step, the resolution gets smaller and smaller\n",
    "        # but this is fine because even with fewer piels, the features are more generalized\n",
    "        self.pool1  = nn.MaxPool2d(2)      #                  -> [B,32,112,112]\n",
    "\n",
    "        # 32 - 64 - 128 - 256 (are the features)\n",
    "        # why more channels as we move on? \n",
    "        self.stage2 = ConvBlock(32,  64)   # -> [B,64,112,112]\n",
    "        self.pool2  = nn.MaxPool2d(2)      # -> [B,64,56,56]\n",
    "\n",
    "        self.stage3 = ConvBlock(64, 128)   # -> [B,128,56,56]\n",
    "        self.pool3  = nn.MaxPool2d(2)      # -> [B,128,28,28]\n",
    "\n",
    "        self.stage4 = ConvBlock(128,256)   # -> [B,256,28,28]\n",
    "        self.pool4  = nn.MaxPool2d(2)      # -> [B,256,14,14]\n",
    "\n",
    "        # Global average pooling → [B,256,1,1]\n",
    "        # we already have many pools, the function above just grabs the average\n",
    "        # adaptive because regardless of inputsize it always returns a 1x1\n",
    "        self.gap    = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # randomly zeros a fraction p\n",
    "        # prevents classifier on depending on a small set of features \n",
    "        self.drop   = nn.Dropout(p=dropout_p)\n",
    "        # linear layer to finish it off \n",
    "        # conv blocks: 32 -> 64 -> 128 -> 256\n",
    "        # linear block: 256 -> 5 (5 classes)\n",
    "        self.fc     = nn.Linear(256, n_classes)  # 5 logits for multi-label\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.stage1(x))\n",
    "        x = self.pool2(self.stage2(x))\n",
    "        x = self.pool3(self.stage3(x))\n",
    "        x = self.pool4(self.stage4(x))\n",
    "        # calculates the average pooling\n",
    "        x = self.gap(x)                 # shape: [B,256,1,1] output: \n",
    "        # flatten is just reshaping the output into torch understandable ones\n",
    "        x = torch.flatten(x, 1)         # [B,256]\n",
    "        # zeros features\n",
    "        x = self.drop(x)\n",
    "        # get the actual logits\n",
    "        logits = self.fc(x)             # [B,5] (raw scores, not sigmoid) [0.42,0.456,0.5387,..,..\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051fb989-001f-4e8a-98a4-785403a8870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer=None):\n",
    "    \"\"\"\n",
    "    Train if optimizer is provided; else evaluate.\n",
    "    Returns: average loss, list of all targets, list of all probs\n",
    "    \"\"\"\n",
    "    train_mode = optimizer is not None\n",
    "    model.train() if train_mode else model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_targets, all_probs = [], []\n",
    "\n",
    "    with torch.set_grad_enabled(train_mode):\n",
    "        for imgs, targets in loader: # train_df\n",
    "            # remember, we work on the gpu\n",
    "            # so we move all the data that we're working with\n",
    "            # to the gpu\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            # get our initial predictions\n",
    "            logits = model(imgs)               # [B,5]\n",
    "            # calculate loss\n",
    "            loss = loss_function(logits, targets)  # scalar\n",
    "\n",
    "            # our usual step \n",
    "            if train_mode:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            # store probs for metrics 2.581 -> 0.43\n",
    "            # turn logits into probabilities called at [0,1]\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy() # detach moves probs from gpu to cpu to turn it into numpy array [1,2,3,4]\n",
    "            # we dont want to use gpu unless its for parallel tasks\n",
    "\n",
    "            # caches the data\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    N = len(loader.dataset)\n",
    "    avg_loss = total_loss / max(1, N)\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    return avg_loss, all_targets, all_probs\n",
    "\n",
    "def multilabel_metrics(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"\n",
    "    y_true: [N,5] {0,1}\n",
    "    y_prob: [N,5] [0..1]\n",
    "    NORM, MI, STTC, HYP, CD\n",
    "    75% 25%\n",
    "\n",
    "    [0,1,1,0,0]\n",
    "    [0,1,0,0,1]\n",
    "    precision: of all the cases we called (flagged) positive, how many are truly positive?\n",
    "    recall: of all the positive cases that exist, how many did we catch?\n",
    "    \n",
    "    f1 (micro and macro): harmonic mean of prec & rec (fairness/balance score)\n",
    "\n",
    "    if u try to catch everything, we might get tons of false alarms or super picky so that u miss real cases\n",
    "    your f1 score will suck, it needs balance\n",
    "    \n",
    "    f1 macro: used to deal with imbalance. coast on common cases and fail on rarities (75-25)\n",
    "    f1 micro: similar to what we're used to. tally every answer/flags and judge\n",
    "\n",
    "    evaluate behavior not only results\n",
    "    \n",
    "    if macro is low but micro is high: fix rare cases\n",
    "    if both are low: more data (more batches, higher res, etc), ecg augmentations, better lr schedules\n",
    "    \"\"\"\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    # Per-class precision/recall/F1\n",
    "    # prec, rec, f1, support (no. occurences of each label in y_true)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
    "    macro_f1 = f1.mean()\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    # AUROC per class (guard against classes with single label value)\n",
    "    \"\"\"\n",
    "    thresholds are important too: yes/no decided by probability (0.7 +-) \n",
    "    low threshold: more data is accepted (precision down, recall up)\n",
    "    high threshold: less data is accepted (recall down, precision up)\n",
    "\n",
    "    ROC vs PR Curves (uses thresholds)\n",
    "    NORM, MI, STTC, HYP, CD\n",
    "    0.7, 0.3, 0.2, 0.5, 0.9 (threshold = 0.5)\n",
    "    Y, N, N, Y, Y\n",
    "\n",
    "    ROC: broad sense of seperability (principle) \"do the beeps get louder for more dangerous items\"\n",
    "    1, 0.5, 0.7,0.2,0.1\n",
    "\n",
    "    PR: precision vs recall (how clean are my positives as i try to catch more?)\n",
    "    use when positives are rare (we obviously want to let more data flood)\n",
    "    pr shows us the tradeoffs (more false alarms) when we raise our recall (accept more data)\n",
    "    punishes \"crying wolf\"\n",
    "\n",
    "    roc is like a thesis statement (do spam eails tend to get higher spam scores than normal emails)\n",
    "    pr is a proposed solution (if i flag more emails as spam to catch all spam (high recall), do i accidentally flag\n",
    "    a lot more real emails (low precision)?\n",
    "\n",
    "    F1 at a tuned threshold: “given a chosen operating point, how balanced are my actual yes/no decisions?\"    \n",
    "\n",
    "    these 3 don't necessarily work together but looking at all of them gives us multiple perspectives\n",
    "    \"\"\"\n",
    "    aurocs = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if len(np.unique(y_true[:, i])) == 2:\n",
    "            aurocs.append(roc_auc_score(y_true[:, i], y_prob[:, i]))\n",
    "        else:\n",
    "            aurocs.append(float('nan'))\n",
    "    return {\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"per_class_f1\": dict(zip(CLASS_ORDER, f1)),\n",
    "        \"per_class_precision\": dict(zip(CLASS_ORDER, prec)),\n",
    "        \"per_class_recall\": dict(zip(CLASS_ORDER, rec)),\n",
    "        \"per_class_auroc\": dict(zip(CLASS_ORDER, aurocs)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc8b7c4-f22e-4670-b67a-095f8e5a3e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_array_api.py:399: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# our scheculer keeps a history of the losses\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# if the losses dont improve, we adjust LR\u001b[39;00m\n\u001b[1;32m     25\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n\u001b[0;32m---> 27\u001b[0m metrics \u001b[38;5;241m=\u001b[39m multilabel_metrics(y_true, y_prob, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacroF1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  microF1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val:\n",
      "Cell \u001b[0;32mIn[9], line 76\u001b[0m, in \u001b[0;36mmultilabel_metrics\u001b[0;34m(y_true, y_prob, threshold)\u001b[0m\n\u001b[1;32m     73\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_prob \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Per-class precision/recall/F1\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# prec, rec, f1, support (no. occurences of each label in y_true)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m prec, rec, f1, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m f1\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     78\u001b[0m micro_f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[0;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1596\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m   1595\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m-> 1596\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m _tolist(unique_labels(y_true, y_pred))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:99\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m     98\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/multiclass.py:417\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    415\u001b[0m     data \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39many(data \u001b[38;5;241m!=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m--> 417\u001b[0m         _assert_all_finite(data, input_name\u001b[38;5;241m=\u001b[39minput_name)\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    121\u001b[0m     X,\n\u001b[1;32m    122\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    123\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    124\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    125\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    126\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    127\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "model = ECGStripCNN(n_classes=5, dropout_p=0.3).to(device)\n",
    "\n",
    "# Loss: multi-label\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # pos_weight from earlier step\n",
    "# Optimizer & scheduler (tweak LR as you like)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# start with somewhat high LR, this helps learn faster and detect bigger patterns\n",
    "# once we start to reach a plateau on accuracy\n",
    "# the lr is adaptively reduced, smller learning rates help with finer pattern detection (in this case)\n",
    "# runs until the end of epochs if no plateau, but if plateau even after the below function, we quit process early to save time and resources\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Train as before\n",
    "EPOCHS = 10\n",
    "best_val = float('inf')\n",
    "best_path = os.path.join(OUT_ROOT, \"best_custom_cnn_multilabel.pt\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # training (as usual)\n",
    "    train_loss, _, _ = run_epoch(model, train_dl, optimizer=optimizer)   # uses your earlier utility\n",
    "    # validation is training on unseen data\n",
    "    val_loss, y_true, y_prob = run_epoch(model, val_dl, optimizer=None)\n",
    "    # our scheculer keeps a history of the losses\n",
    "    # if the losses dont improve, we adjust LR\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    metrics = multilabel_metrics(y_true, y_prob, threshold=0.5)\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n",
    "          f\"macroF1={metrics['macro_f1']:.3f}  microF1={metrics['micro_f1']:.3f}\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save({\"model_state\": model.state_dict(),\n",
    "                    \"class_order\": CLASS_ORDER}, best_path)\n",
    "        print(f\"  ↳ saved best to {best_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1643e75-b8bd-453d-8933-a11e786d1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "FINE tuning:\n",
    "0. epochs\n",
    "1. dropout\n",
    "2. lr\n",
    "3. weight decay\n",
    "4. factor (scheduler)\n",
    "6. patience (scheduler)\n",
    "7. more feature classes in ConvBlock\n",
    "8. more layers for convblock\n",
    "9. image augmentation\n",
    "10. increase data size, increase image resolution, change to higher bitrate\n",
    "\"\"\"\n",
    "\n",
    "ckpt = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "test_loss, y_true_test, y_prob_test = run_epoch(model, test_dl, optimizer=None)\n",
    "test_metrics = multilabel_metrics(y_true_test, y_prob_test, threshold=0.5)\n",
    "\n",
    "# Compute simple accuracies\n",
    "threshold = 0.5\n",
    "y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "exact_match = np.all(y_pred_test == y_true_test, axis=1)\n",
    "exact_acc = exact_match.mean() * 100\n",
    "labelwise_acc = (y_pred_test == y_true_test).mean() * 100\n",
    "\n",
    "print(f\"\\nTest loss={test_loss:.4f}\")\n",
    "print(f\"MacroF1={test_metrics['macro_f1']:.3f}  MicroF1={test_metrics['micro_f1']:.3f}\")\n",
    "print(f\"Exact-match accuracy: {exact_acc:.2f}%\")\n",
    "print(f\"Label-wise mean accuracy: {labelwise_acc:.2f}%\")\n",
    "print(\"Per-class F1:\", test_metrics[\"per_class_f1\"])\n",
    "print(\"Per-class AUROC:\", test_metrics[\"per_class_auroc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
